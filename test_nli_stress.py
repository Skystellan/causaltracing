import torch
import random
from transformers import AutoTokenizer, AutoModelForSequenceClassification

def run_logic_breakdown():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if torch.backends.mps.is_available(): device = torch.device("mps")
    
    # ä½¿ç”¨ä½ è®ºæ–‡ä¸­çš„å¼ºåŠ›æ¨¡å‹
    model_name = "MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli"
    print(f"Loading {model_name}...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)
    
    # æ—¢ç„¶ v3 åœ¨ 512 å†…è§†åŠ›æ— æ•Œï¼Œæˆ‘ä»¬å°±åœ¨å®ƒçš„èˆ’é€‚åŒº(512)å†…æ”»å‡»å®ƒçš„é€»è¾‘æ­»ç©´
    MAX_LEN = 512
    
    print("\n" + "="*80)
    print("ğŸ§  LOGIC BREAKDOWN PROBE: STATE MUTATION & CONDITIONAL LOGIC")
    print("Hypothesis: V3 sees all facts, but cannot handle 'Overwrite' or 'Condition'.")
    print("="*80)

    scenarios = ["Chronological_Overwrite", "Conditional_Trap"]
    
    for scenario in scenarios:
        correct = 0
        samples = 50 
        print(f"\n>>> Running Scenario: {scenario}")
        
        for _ in range(samples):
            # ==================================================================
            # åœºæ™¯ A: â³ æ—¶åºè¦†ç›– (Chronological Overwrite)
            # éš¾ç‚¹ï¼šåŒä¸€ä¸ªå®ä½“æœ‰å¤šä¸ªçŠ¶æ€ï¼Œæ¨¡å‹å¿…é¡»è¯†åˆ«â€œæœ€æ–°â€çš„é‚£ä¸ª
            # ==================================================================
            if scenario == "Chronological_Overwrite":
                entity = f"Ticket-{random.randint(1000,9999)}"
                
                # å®šä¹‰ä¸‰ä¸ªçŠ¶æ€
                status_old = "Open"
                status_mid = "In-Progress"
                status_new = "Closed" # çœŸç† (Truth)
                
                # æ„é€ æ—¥å¿—æµ (Log Stream)
                # 1. æ—©æœŸæ—¥å¿— (Old - Distractor)
                log_1 = f"Timestamp 08:00: System auto-generated {entity} with status {status_old}."
                # 2. ä¸­æœŸæ—¥å¿— (Mid - Distractor)
                log_2 = f"Timestamp 12:00: Engineer updated {entity} to status {status_mid}."
                # 3. æ™šæœŸæ—¥å¿— (New - Ground Truth)
                log_3 = f"Timestamp 18:00: Final resolution applied. {entity} status is now {status_new}."
                
                # å¡«å……å™ªéŸ³ (è®©æ¨¡å‹æ— æ³•ä»…é è·ç¦»åˆ¤æ–­ï¼Œè€Œæ˜¯å¿…é¡»ç†è§£ update é€»è¾‘)
                distractors = []
                for i in range(15):
                    d_id = f"Ticket-{random.randint(1000,9999)}"
                    d_stat = random.choice(["Open", "Closed", "Error"])
                    distractors.append(f"Log: {d_id} is {d_stat}.")
                
                # æ‹¼è£…ï¼šOld -> Noise -> Mid -> Noise -> New
                # æ‰€æœ‰çš„çŠ¶æ€éƒ½åœ¨ Context é‡Œï¼Œæ¨¡å‹éƒ½èƒ½"çœ‹è§"ã€‚
                split = len(distractors)//2
                context = f"{log_1} {' '.join(distractors[:split])} {log_2} {' '.join(distractors[split:])} {log_3}"
                
                # æ”»å‡»ï¼šæ‹¿ç€â€œæ—§çŠ¶æ€â€å»é—®æ¨¡å‹ (è¯±å¯¼å®ƒ Entailment)
                # äº‹å®æ˜¯ Closedï¼Œæ‰€ä»¥ Open æ˜¯ Contradiction
                if random.random() > 0.5:
                    hyp = f"{entity} is currently {status_old}."
                    expected = "Contradiction" 
                else:
                    hyp = f"{entity} is currently {status_new}."
                    expected = "Entailment"

            # ==================================================================
            # åœºæ™¯ B: ğŸš¦ æ¡ä»¶é™·é˜± (Conditional Trap)
            # éš¾ç‚¹ï¼šIf A then B. æ–‡ä¸­åªæœ‰ A' (ä¼¼æ˜¯è€Œé)ã€‚
            # ==================================================================
            elif scenario == "Conditional_Trap":
                code = random.randint(100, 999)
                target_color = "RED"
                
                # è§„åˆ™ï¼šåªæœ‰çº¢ç¯äº®ï¼Œå¯†ç æ‰æ˜¯ code
                rule = f"Security Protocol: The access code is {code} ONLY IF the alert light is {target_color}."
                
                # äº‹å®ï¼šç»¿ç¯äº®äº†
                fact = f"System Report: Currently, the alert light is GREEN."
                
                # å¹²æ‰°é¡¹ï¼šå¤§é‡çš„ If...Then...
                distractors = []
                colors = ["BLUE", "YELLOW", "PURPLE"]
                for c in colors:
                    d_code = random.randint(100, 999)
                    distractors.append(f"Rule: Code is {d_code} if light is {c}.")
                
                context = f"{rule} {' '.join(distractors)} {fact}"
                
                # æ”»å‡»ï¼šé—®å¯†ç æ˜¯ä¸æ˜¯ code
                # æ¨¡å‹çœ‹åˆ°äº† "Code is {code}" (åœ¨è§„åˆ™é‡Œ)ï¼Œä¹Ÿçœ‹åˆ°äº† "Light is GREEN" (åœ¨äº‹å®é‡Œ)
                # å®ƒéœ€è¦åšæ¨ç†ï¼šRED != GREEN -> Condition False -> Code Not Valid
                hyp = f"The access code is {code}."
                expected = "Not_Entailment" # åº”è¯¥æ˜¯ Neutral æˆ– Contradictionï¼Œç»ä¸æ˜¯ Entailment

            # --- ç¼–ç ä¸æˆªæ–­ä¿æŠ¤ ---
            inputs = tokenizer(context, hyp, return_tensors="pt", truncation=True, max_length=MAX_LEN).to(device)
            
            # å®Œæ•´æ€§è‡ªæ£€ï¼šç¡®ä¿å…³é”®ä¿¡æ¯(æ–°çŠ¶æ€/æ¡ä»¶)éƒ½åœ¨
            decoded = tokenizer.decode(inputs.input_ids[0])
            if scenario == "Chronological_Overwrite":
                if status_new not in decoded: continue 
            elif scenario == "Conditional_Trap":
                if "GREEN" not in decoded or str(code) not in decoded: continue

            # --- æ¨ç† ---
            with torch.no_grad():
                out = model(**inputs)
            
            pred_label = model.config.id2label[torch.argmax(out.logits).item()]
            
            # å®½æ¾åˆ¤å®š (Robust Evaluation)
            is_correct = False
            if expected == "Entailment":
                if "entailment" in pred_label.lower(): is_correct = True
            elif expected == "Contradiction":
                if "contradiction" in pred_label.lower(): is_correct = True
            elif expected == "Not_Entailment":
                # åªè¦ä¸æ˜¯ Entailment å°±ç®—å¯¹ (Neutral/Contradiction éƒ½æ˜¯åˆç†çš„æ‹’ç»)
                if "entailment" not in pred_label.lower(): is_correct = True 
            
            if is_correct: correct += 1
        
        acc = correct / samples * 100
        print(f"Scenario Accuracy: {acc:.1f}%")
        
        if acc < 85:
            print(f"   >>> ğŸ’¥ CRITICAL HIT: Model failed logic/state reasoning in {scenario}.")

if __name__ == "__main__":
    run_logic_breakdown()